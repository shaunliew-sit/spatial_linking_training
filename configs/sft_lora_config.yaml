# =============================================================================
# Spatial Linking HOI Training Configuration
# =============================================================================
# Matches LLaMA-Factory style configuration for easy migration
# Reference: verl-tool/examples/train/hoi/hoi_cof_sft_lora.yaml

# =============================================================================
# Model Configuration
# =============================================================================
model_name_or_path: Qwen/Qwen3-VL-8B-Instruct
trust_remote_code: true

# Vision settings
image_max_pixels: 1048576  # 1024x1024 max resolution

# =============================================================================
# LoRA Configuration
# =============================================================================
finetuning_type: lora
lora_rank: 64
lora_alpha: 128
lora_target: all  # Options: all, or comma-separated: q_proj,v_proj,k_proj,o_proj
lora_dropout: 0.05

# =============================================================================
# Freezing Strategy
# =============================================================================
freeze_vision_tower: true           # Freeze vision encoder
freeze_multi_modal_projector: false # Keep projector trainable
train_spatial_linking: true         # Train spatial linking module (always true)

# =============================================================================
# Dataset Configuration
# =============================================================================
# Paths to SFT data files
spatial_sft_file: /dataset/spatial_sft_data.json
cof_sft_file: /dataset/cof_tool_sft_data.json

# Image paths
image_base_dir: /dataset

# Validation split
val_ratio: 0.05

# =============================================================================
# Training Hyperparameters
# =============================================================================
# Learning rate
learning_rate: 2.0e-5

# Epochs and batch size
num_train_epochs: 3
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 16  # Effective batch size = 2 * 16 = 32

# Optimizer
optim: adamw_torch
weight_decay: 0.01

# Learning rate schedule
warmup_ratio: 0.1
lr_scheduler_type: cosine

# Sequence length
cutoff_len: 2048

# =============================================================================
# Precision and Memory
# =============================================================================
bf16: true
fp16: false
gradient_checkpointing: true

# =============================================================================
# Logging and Saving
# =============================================================================
output_dir: ./outputs/spatial_linking_sft
logging_steps: 10
save_strategy: epoch
save_total_limit: 3
eval_strategy: epoch

# =============================================================================
# WandB Configuration
# =============================================================================
report_to: wandb
wandb_project: spatial-linking-hoi
run_name: spatial_linking_lora_sft

# =============================================================================
# Advanced Options
# =============================================================================
# Preprocessing
preprocessing_num_workers: 4

# Seed for reproducibility
seed: 42

# Remove unused columns (important for VLM training)
remove_unused_columns: false
